import streamlit as st
import os
from rag_engine import RAGSystem
from chatbot import GeminiBot

# Page configuration
st.set_page_config(page_title="Tr·ª£ L√Ω Ph√°p Lu·∫≠t AI (Pinecone)", page_icon="‚öñÔ∏è", layout="wide")

# Custom CSS for styling
st.markdown("""
<style>
    .main {
        background-color: #f0f2f6;
    }
    .stChatInput {
        position: fixed;
        bottom: 3rem;
    }
    .chat-message {
        padding: 1.5rem; border-radius: 0.5rem; margin-bottom: 1rem; display: flex
    }
    .chat-message.user {
        background-color: #2b313e; color: #ffffff;
    }
    .chat-message.bot {
        background-color: #ffffff; color: #000000;
    }
</style>
""", unsafe_allow_html=True)

# Initialize Session State
if "messages" not in st.session_state:
    st.session_state.messages = []
if "rag_system" not in st.session_state:
    st.session_state.rag_system = None
if "vector_db_ready" not in st.session_state:
    st.session_state.vector_db_ready = False

# Sidebar
with st.sidebar:
    st.title("‚öñÔ∏è C·∫•u H√¨nh")
    
    st.subheader("C·∫•u h√¨nh API")
    gemini_api_key = st.text_input("Gemini API Key", type="password")
    pinecone_api_key = st.text_input("Pinecone API Key", type="password")
    pinecone_index_name = st.text_input("Pinecone Index Name", value="legal-chatbot")
    
    if st.button("K·∫øt N·ªëi Database"):
        if pinecone_api_key and pinecone_index_name:
            st.session_state.rag_system = RAGSystem(pinecone_api_key, pinecone_index_name)
            with st.spinner("ƒêang k·∫øt n·ªëi ƒë·∫øn Pinecone..."):
                if st.session_state.rag_system.load_index():
                    st.session_state.vector_db_ready = True
                    st.toast("ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng ƒë·∫øn Pinecone!", icon="‚úÖ")
                else:
                    st.session_state.vector_db_ready = False
                    st.toast("Ch∆∞a t√¨m th·∫•y index ho·∫∑c index r·ªóng. Vui l√≤ng t·∫£i l√™n t√†i li·ªáu.", icon="‚ö†Ô∏è")
        else:
            st.warning("Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß th√¥ng tin Pinecone.")

    st.subheader("T√†i Li·ªáu Ph√°p Lu·∫≠t")
    uploaded_files = st.file_uploader("T·∫£i l√™n t√†i li·ªáu (PDF/TXT)", accept_multiple_files=True, type=['pdf', 'txt'])
    
    if st.button("X·ª≠ L√Ω & Upload T√†i Li·ªáu"):
        if uploaded_files and pinecone_api_key and pinecone_index_name:
            # Ensure RAG system is initialized
            if st.session_state.rag_system is None:
                st.session_state.rag_system = RAGSystem(pinecone_api_key, pinecone_index_name)
            
            with st.spinner("ƒêang x·ª≠ l√Ω v√† upload l√™n Pinecone..."):
                documents = st.session_state.rag_system.load_documents(uploaded_files)
                if documents:
                    st.session_state.rag_system.create_vector_db(documents)
                    st.session_state.vector_db_ready = True
                    st.success(f"ƒê√£ x·ª≠ l√Ω v√† l∆∞u {len(documents)} trang t√†i li·ªáu v√†o Pinecone!")
                else:
                    st.error("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c t√†i li·ªáu n√†o.")
        elif not (pinecone_api_key and pinecone_index_name):
            st.warning("Vui l√≤ng nh·∫≠p API Key v√† Index Name.")
        else:
            st.warning("Vui l√≤ng t·∫£i l√™n √≠t nh·∫•t m·ªôt t√†i li·ªáu.")

    st.markdown("---")
    st.markdown("### H∆∞·ªõng D·∫´n")
    st.markdown("1. Nh·∫≠p API Keys (Gemini & Pinecone).")
    st.markdown("2. Nh·∫•n 'K·∫øt N·ªëi Database' ƒë·ªÉ d√πng d·ªØ li·ªáu c≈©.")
    st.markdown("3. Ho·∫∑c t·∫£i t√†i li·ªáu m·ªõi v√† nh·∫•n 'X·ª≠ L√Ω & Upload'.")
    st.markdown("4. B·∫Øt ƒë·∫ßu chat!")

# Main Chat Interface
st.title("Tr·ª£ L√Ω T∆∞ V·∫•n Ph√°p Lu·∫≠t Vi·ªát Nam üáªüá≥")
st.caption("S·ª≠ d·ª•ng c√¥ng ngh·ªá RAG + Gemini + Pinecone")

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Chat Input
if prompt := st.chat_input("B·∫°n c·∫ßn t∆∞ v·∫•n v·ªÅ v·∫•n ƒë·ªÅ g√¨?"):
    # Add user message to history
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Generate response
    if not gemini_api_key:
        response = "Vui l√≤ng nh·∫≠p Gemini API Key trong thanh b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu."
    elif not st.session_state.vector_db_ready:
        response = "Vui l√≤ng k·∫øt n·ªëi ƒë·∫øn Pinecone ho·∫∑c t·∫£i l√™n t√†i li·ªáu tr∆∞·ªõc."
    else:
        with st.chat_message("assistant"):
            with st.spinner("ƒêang suy nghƒ©..."):
                # Retrieve context
                # Ensure rag_system is initialized if it wasn't (e.g. page refresh but session kept?)
                # Actually session_state persists, so it should be fine.
                if st.session_state.rag_system:
                    context_chunks = st.session_state.rag_system.retrieve(prompt)
                    
                    # Generate answer
                    bot = GeminiBot(gemini_api_key)
                    response = bot.generate_response(prompt, context_chunks)
                    st.markdown(response)
                    
                    # Show sources (optional)
                    with st.expander("Xem ngu·ªìn tham kh·∫£o"):
                        for i, doc in enumerate(context_chunks):
                            st.markdown(f"**Ngu·ªìn {i+1}:**")
                            st.markdown(doc.page_content[:300] + "...")
                else:
                    response = "L·ªói: H·ªá th·ªëng ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o. Vui l√≤ng k·∫øt n·ªëi l·∫°i."
                    st.error(response)

    # Add assistant message to history
    st.session_state.messages.append({"role": "assistant", "content": response})
